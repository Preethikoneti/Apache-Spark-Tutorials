{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName=\"rdd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1st RDD\n",
    "rdd = sc.textFile(\"file:///home/aditya/GitHub Projects/Spark-Tutorials/Resources/sample.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeBeautiful(para):\n",
    "    lower_para = para.lower()\n",
    "    words = lower_para.split()\n",
    "    return words\n",
    "#2nd RDD using flatmap Transformation\n",
    "words = rdd.flatMap(makeBeautiful)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatmap vs map\n",
    "#### map\n",
    "1. map transforms an RDD of length N into another RDD of length N.\n",
    "\n",
    "#### flatMap\n",
    "1. flatMap (loosely speaking) transforms an RDD of length N into a collection of N collections, then flattens these into a single RDD of results.\n",
    "2. Example - [\"aa bb cc\", \"\", \"dd\"] => [[\"aa\",\"bb\",\"cc\"],[],[\"dd\"]] => [\"aa\",\"bb\",\"cc\",\"dd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'plan', 'was', 'chett’s.', 'he']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take is an action- which takes initial n results\n",
    "words.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['plan', 'chett’s.', 'clever', 'one;', 'he’d']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "#3rd RDD using filter transformation for stopwords\n",
    "wordsrdd = words.filter(lambda x: x not in stopwords)\n",
    "wordsrdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter\n",
    "1. filter select only element which satisfies given condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cle : ['clever']\n",
      "ste : ['steward', 'steep']\n",
      "fou : ['four']\n",
      "bas : ['bastard']\n",
      "jon : ['jon']\n"
     ]
    }
   ],
   "source": [
    "#4th RDD using groupBy transformation\n",
    "groupsRDD = wordsrdd.groupBy(lambda w : w[0:3])\n",
    "for initals,grp in groupsRDD.take(5):\n",
    "    print(\"{} : {}\".format(initals,list(grp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GroupBy\n",
    "1. form groups take a function which return a unique value on basis of which groups are formed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wou : ['wouldn’t', 'would', 'would', 'would', 'would', 'would', 'would', 'would']\n",
      "old : ['old', 'old', 'old', 'old', 'old']\n",
      "cou : ['could', 'cousins', 'could', 'cousins.']\n",
      "don : ['done', 'donnel', 'done']\n",
      "che : ['chett’s.', 'chett', 'chett']\n"
     ]
    }
   ],
   "source": [
    "#5th RDD using sortBy transformation\n",
    "sortedgrps = groupsRDD.sortBy(lambda x: -1*len(x[1]))\n",
    "for initals,grp in sortedgrps.take(5):\n",
    "    print(\"{} : {}\".format(initals,list(grp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SortBy\n",
    "1. Also takes a function and returns a integer on basis of which sorted RDD is formed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6, 8, 10]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allint = sc.parallelize(range(1,1000000))\n",
    "evenint = allint.filter(lambda x: x%2==0)\n",
    "evenint.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "499999"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evenint.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249999500000\n"
     ]
    }
   ],
   "source": [
    "evensum = evenint.reduce(lambda x,y:x+y)\n",
    "print(evensum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parallel processing is achieved by spark by using shared Variables\n",
    "1. BroadCast Shared Variables - \n",
    "    * These variables are used to save copy of data across all nodes.\n",
    "2. Accumulator Shared Variables- \n",
    "    * These vaiables are used to aggregate information through associate and cummultative operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Class Storage Level Decides how RDDs should be stored\n",
    "1. In memory or Disk\n",
    "2. Serialize or Replicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[946829, 525297, 868228, 963597, 425375]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample5 = allint.takeSample(True,5,seed=5)\n",
    "sample5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sample\n",
    "1. takeSample(withReplacement,num,seed=None)\n",
    "2. take sample of num elements from a rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "print(allint.take(5))\n",
    "allint.filter(lambda x: x<15).foreach(lambda x: print(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
